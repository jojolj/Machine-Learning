{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a90d93c-b56f-457a-851b-c9f2d4142dd4",
   "metadata": {},
   "source": [
    "# Backbone networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0c8d5-7564-46af-abf4-a3a600cd31db",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "### ImageNet\n",
    "\n",
    "The ImageNet (see [the Web site](https://www.image-net.org/)) dataset was the first large enough dataset to train large deep learning networks. Before ImageNet there were other similar datasets that inspired the collection of ImageNet:\n",
    "\n",
    " * Caltech-101 (101 categories, 10k images, by CalTech Uni)\n",
    " * Pascal VOC (20 categories, 10k images, by EU project led by Oxford)\n",
    "\n",
    "ImageNet (by Standford Uni) included 1M images of 1k categories annotated according to the [WordNet](https://en.wikipedia.org/wiki/WordNet) nouns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af03cfd-5410-4de1-9d08-13d86e7a0508",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "\n",
    "The main driving force that boosted research on deep learning was the AlexNet architecture published in 2012 NeurIPS paper. Many still valid ideas were presented in that paper, and this kind of networks trained for semantic classification tasks and multipurpose tools for computer vision and audio analysis. AlexNet won the ILSVRC 2012 competition and their amazing and worldbreaking results are still available in the ImageNet server:\n",
    "\n",
    " * https://www.image-net.org/challenges/LSVRC/2012/results.html\n",
    "\n",
    "See also the original paper:\n",
    "\n",
    " * Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (2012): \"ImageNet Classification with Deep Convolutional Neural Networks\". In Proc. of the NeurIPS. URL: https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\n",
    "\n",
    "<div>\n",
    "<img src=\"pictures/alexnet.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e23b3-fb02-4b66-9bb7-7659972a392d",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"pictures/alexnet_parameters_table.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b9767-c2ef-461c-8d62-ffef25df9142",
   "metadata": {},
   "source": [
    "## VGGNet\n",
    "\n",
    "In their paper the Oxford group investigated various strategies to build a better backbone network for image classification and proposed VGGNet which is many ways simplified version of AlexNet.\n",
    "\n",
    " * Karen Simonyan, Andrew Zisserman (2015): \"Very Deep Convolutional Networks for Large-Scale Image Recognition\". In Proc. of the ICLR. URL: https://arxiv.org/abs/1409.1556\n",
    "\n",
    "<div>\n",
    "<img src=\"pictures/vggnet_table.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c24b71-40be-4da6-827e-b1056909ee2a",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    " * Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun (2016): \"Deep Residual Learning for Image Recognition\". In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). [PDF](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n",
    "\n",
    "<div>\n",
    "    <img src=\"pictures/resnet_34_layers.png\" height=400/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c535f2a-32ba-42f4-bbbe-8e6704f890f4",
   "metadata": {},
   "source": [
    "## Other backbones\n",
    "\n",
    "The success of these three backbones boosted research on new backbones with distinct features\n",
    "\n",
    " * MobileNet\n",
    " * SqueezeNet\n",
    "\n",
    "and also other modalities such as audio backbones\n",
    "\n",
    " * OpenL3\n",
    " * PANNs\n",
    " * PaSST\n",
    "\n",
    "or specifically for speech\n",
    "\n",
    " * wac2vec 2.0\n",
    "\n",
    "Moreover, new dataset has been collected and annotated:\n",
    "\n",
    " * MS COCO by Microsoft (similar to ImageNet)\n",
    " * DCASE by Tampere University (for audio recognition)\n",
    " * AudioSet by Google (similar to DCASE)\n",
    "\n",
    "There exist many more for audio and video, and also other new large scale datasets. What is the meaning of filters in the deep hierarchy:\n",
    "\n",
    "See:\n",
    " * YouTube: [Jurney on the Deep Dreams](https://www.youtube.com/watch?v=SCE-QeDfXtA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d07ccd-63af-4f9d-8a6b-4f1031794193",
   "metadata": {},
   "source": [
    "## Using backbones\n",
    "\n",
    "You can use them directly or as the feature extraction body for your own application.\n",
    "\n",
    "**Example:** AlexNet image classification\n",
    "\n",
    " * [Colab notebook](https://colab.research.google.com/drive/1PXpSA9qy9Kr-4Jh-Pe44FUDaHXr4MtJO?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c0f95c-5f63-498f-9911-96c3b5f328e4",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "See the original articles of the backbone networks to learn more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
