{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46d367d86bf72819161dcfb8c62052eb",
     "grade": false,
     "grade_id": "cell-5d6eec3ea831c70b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1 align=\"center\">Bonus task <br> Tissue type classification based on microarray gene expression profiles</h1>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>CS-EJ3211 Machine Learning with Python 29.5.-17.7.2023</center>\n",
    "<center>Aalto University (Espoo, Finland)</center>\n",
    "<center>fitech.io (Finland)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "084910f63523639f0cf72730566f6193",
     "grade": false,
     "grade_id": "cell-ac2ed402b9a09b88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2><strong>Submit a notebook by 24.07.2023 at jupyter hub aalto. Follow the required outline presented in this notebook.</strong></h2>\n",
    "\n",
    "The submitted notebook should contain all Python code used in the project (early prototyping and \"scrapbooking\" can be excluded). The notebook should be arranged so that the reader can replicate your workflow by running the cells in the notebook in order.\n",
    "\n",
    "You can get 15p max (problem formulation - 2p, methods - 3p, implementation - 5p, results - 2.5p, conclutions - 2.5p) for this notebook.  \n",
    "\n",
    "**General recommendations**\\\n",
    "Strive to use the notation used on this course if you use mathematical formulas or symbols. In the case that you want to use different notation, use good scientific writing principles and clearly define the meaning of your symbols.\n",
    "\n",
    "**Please comment your code.**\\\n",
    "The commenting doesn't have to be as comprehensive as it is in the exercise rounds (where it is for educational reasons), but it should give some indication of the what is happening in different sections of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51aabd2519c175b0cb5c2cde44618ce0",
     "grade": false,
     "grade_id": "cell-382d15fc92e81821",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "\"A microarray is a laboratory tool used to detect the expression of thousands of genes at the same time. DNA microarrays are microscope slides that are printed with thousands of tiny spots in defined positions, with each spot containing a known DNA sequence or gene.\"\\\n",
    "text source: https://www.nature.com/scitable/definition/microarray-202/\n",
    "\n",
    "<img src=\"../../../coursedata/7_bonus_notebook/DNA_microarray.jpg\" width=800/>\n",
    "\n",
    "image source: https://www.genome.gov/about-genomics/fact-sheets/DNA-Microarray-Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1b526da928adbb28d5c6aa0607ec90e",
     "grade": false,
     "grade_id": "cell-bbb7fa10913ba169",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The microarray data for this problem consists of normalized relative expression of certain genes measured in different tissue. There are 3000 gene probes and 2000 samples. The full dataset can be found at https://www.ebi.ac.uk/arrayexpress/ (accession number E-MTAB-62). \n",
    "\n",
    "The subset of this data is stored as csv file in `/coursedata/7_bonus_notebook/` directory, i.e. use path `\"/coursedata/7_bonus_notebook/data_subset.csv\"` to load the data. \n",
    "\n",
    "The first columns of  'data_subset.csv' file contains ID's of samples (e.g. 'GSM23227.CEL') and analyses info ('RMA') and the rest - expression values for 3000 genes. \n",
    "\n",
    "Your task is to predict the type of tissue ('disease' vs 'normal') based on expression profile of samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb473134757cee559ed851f47778aeee",
     "grade": false,
     "grade_id": "cell-5a43d1031f1ab679",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='problem'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "\n",
    "## Problem formulation (2 p)\n",
    "\n",
    "In contrast to the conceptual presentation of the problem in the introduction, this section formulates the problem as a machine learning problem. You should:\n",
    "\n",
    "- Define the type of your problem. Is it a regression or classification problem? Or perhaps something else?\n",
    "\n",
    "- Define the **data points** in your problem and define the **features** and **labels** of the points.\n",
    "\n",
    "- Define the **metric** that serves as the measure of quality of an ML model on your problem*. For example, the mean squared error might be a reasonable choice for a regression problem, whereas some kind of balanced accuracy score might suit a classification problem with imbalanced classes. Note that this is not necessarily equivalent to the loss function used by your model!\n",
    "    \n",
    "    \n",
    "*More info on metric below.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TEXT HERE\n",
    "\n",
    "Problem formulation ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c60cdf6ebfb27d20c006157a45c1a3c",
     "grade": false,
     "grade_id": "cell-a7755af5fc8be2d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Methods and Implementation instructions.\n",
    "\n",
    "    \n",
    "Your task is to build **logistic regression and Support Vector Machine (SVM) models** for solving tissue type prediction task. During this course, you have familiarized yourself with multiple ML methods from scikit-learn library, but now you will need to independently learn the specifics of how to use the SVM classifier in scikit-learn by studying the documentation and related resources. \n",
    "\n",
    "**Note, that here we are doing model selection and choosing between hypothesis space of logistic regression and several hypothesis spaces of SVM models with different hyperparameters.**\n",
    "    \n",
    "More precisely, you need to:\n",
    "\n",
    "1. Upload the \"data_subset.csv\" file as a Pandas dataframe. The file contains gene expression data for tissues of different types. The first column contains the sample id and the second column indicates how the data was analysed (Robust Multi-array Average or RMA). The remaining columns, excluding the final one, contain the relative gene expression values. Finally, the last column contains the category (label) to which the data points belong to ('cell line', 'disease', 'neoplasm', 'normal'). \n",
    "\n",
    "\n",
    "2. You will only use data points belonging to two of the four categories in the dataset - 'disease' and 'normal'. Consequently, you should create a new data frame that only contains the data points with these labels. The new dataset should consist of 700 data points.\n",
    "\n",
    "\n",
    "3. Create numpy arrays `X` (feature matrix) and `y` (label vector) based on the data frame. The feature matrix should contain the expression data and be of shape `(700, 3000)`.\n",
    "   The label vector `y` should be of shape `(700,)` and contain integer values 1 (for data points labled as \"disease\") and 0 (for data points labled as \"normal\").\n",
    "   \n",
    "   \n",
    "4. Split the data with `train_test_split` into trainval and test sets (with 80:20 ratio, random_state=42). Keep test set aside until final evaluation. Use trainval data for training models and for model selection (as described below). \n",
    "\n",
    "\n",
    "5. Implement PCA (using 20 components) with logistic regression:\n",
    "\n",
    "   - Use Pipeline sklearn class to chain pre-processing steps (StandardScaler() and PCA(n_components=20, random_state=42)) and logistic regression. \n",
    "   - Use [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) class from sklearn.model_selection to perform 5-fold cross-validation and get average F1-score (use parameters scoring='f1' and cv=5 in `cross_val_score` object).\n",
    " \n",
    "\n",
    "6. Implement PCA (using 20 components) with SVM:\n",
    "\n",
    "  - Construct Pipeline object with scaler and PCA for SVM model in a similar way as for logistic regression.\n",
    "  - Use training set for choosing parameters and hyperparameters. Specifically, perform grid search combined with cross-validation on the Pipeline object by using the `GridSearchCV` class in scikit-learn. \n",
    "  \n",
    "  The candidate parameter values for the SVM model in your grid search should be `'C': [0.01, 1, 100]` and `'gamma': [1e-04, 1e-03, 1e-02]}`, the number of folds used for cross-validation should be `cv=5`, and scoring parameter `f1`.\n",
    "  - Report F1-score of SVM model with best parameter values for `C` and `gamma`.\n",
    "  \n",
    "\n",
    "7. Choose model with best F1-score and perform final evaluation:\n",
    "\n",
    "    - Fit model (pipeline object) on the trainval set.\n",
    "    - Report the accuracy and F1-score on the training and test sets.\n",
    "    - Plot a normalized confusion matrix for the test set. \n",
    "\n",
    "Useful links:\n",
    "\n",
    "- Learn about Support Vector Machine (SVM) methods (e.g. https://scikit-learn.org/stable/modules/svm.html#support-vector-machines) and the implementation of SVM (specifically the SVC) in the scikit-learn library.\n",
    "- Pipeline example https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html\n",
    "- Metrics for evaluation https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- Function for plotting confusion matrix https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn-metrics-confusionmatrixdisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd010620d7e62f0259ddf35734113c28",
     "grade": false,
     "grade_id": "cell-730a7b3723d9aa57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='methods'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "\n",
    "## Methods (3p)\n",
    "    \n",
    "This section presents the methods used to solve the machine learning problem and walks through the process of solving the problem. This section could include:\n",
    "\n",
    "- A description of the dataset. What is the source of the dataset? How many data points does it contain? The features and labels where already presented in the previous section but can be presented once again.\n",
    "    \n",
    "- Describe why and how the data split on subsets.\n",
    "\n",
    "- A description of the pre-processing methods that you have used on your data. \n",
    "\n",
    "- A description of the model(s) you are using to solve your machine learning problem. Of what form are the predictor functions (include formula if applicable)? What is the loss function to be minimized or maximized (include formula if applicable). You should also include a short description of the hyperparameters that you tune to optimize the model. \n",
    "    \n",
    "- If you use some tools/methods for model selection and validation (e.g. cross-validation, grid search), explain the purpose of it and how it was performed.\n",
    "    \n",
    "- A description of hyperparameter tuning and model selection process. E.g. which validation methods have you used to estimate the model performance on previously unseen data?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TEXT HERE\n",
    "\n",
    "Methods ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c1a39ea3f9b5861297086a778ee2238",
     "grade": false,
     "grade_id": "cell-c404c6d5ceb2f5a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='methods'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "\n",
    "## Implementation (5p)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============Import all needed libraries===============#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============Import dataset=================#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============Select subset of dataset [only 'disease' and 'normal' categories]=================#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============Split dataset=================#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============Logistic regression===============#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============SVM===============#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============Final evaluation of the chosen model===============#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7e08c8e539c20b16c18428198d4214d",
     "grade": false,
     "grade_id": "cell-b3a69f3f9be5c363",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='result'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "\n",
    "## Results (2.5 p)\n",
    "\n",
    "This section presents the results of the experiments. In most problems, the central result is the estimated performance of the final model on new data with respect to the chosen performance metric. In addition, you can for example, present results for different models or consider how the hyperparameters affect the models performance.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TEXT HERE ###\n",
    "\n",
    "Some text about your results ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43697039452f749b44b0662a27afd598",
     "grade": false,
     "grade_id": "cell-0f1dd77f14980089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='discussion'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "\n",
    "\n",
    "## Discussion/ Conclusions (2.5 p)\n",
    "\n",
    "In this section you should analyze the results on a more general level and summarize the findings of your work. Discuss the following questions:\n",
    "- Do the results suggest satisfactory performance of your final model, or is there much room for improvement?\n",
    "- How do your results compare to benchmarks/ solutions of others (if such are available)?\n",
    "- Are you aware of some methodological shortcomings in the project?\n",
    "- Do you have ideas for how to improve the performance (e.g. using more training data, using more features for the data points, using different class of predictor functions (hypothesis space) ?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TEXT HERE ###\n",
    "\n",
    "Discussion ...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
